---
title: "Analysis of wh-questions"
author: "azaitsu"
date: "October 22, 2020"
output: html_document
---
  
```{r}  
library(ggplot2)
library(stringr)
library(textstem)
library(tidyverse)

# theme_set(theme_bw())

this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
source("../../analysis/helpers.R")
```

Read the database into R and explore it.
```{r}
d = read.table("../results/swbd.tab",sep="\t",header=T,quote="")
```

```{r, look into all the nonfinite questions}

df_nonfinite <- d %>%
  filter(Finite == "no")
nrow(df_nonfinite)/nrow(d)*100
View(df_nonfinite[,c("Item_ID","Sentence")])

str(df_nonfinite$QuestionType)

table(df_nonfinite$QuestionType)


df_nonfin_emb = d %>%
  filter((QuestionType == "embedded") & (Finite == "no"))
# this gives you the number of rows
nrow(df_nonfin_emb)

# this gives you the number of columns...
# a measure for the vector of column names
length(df_nonfin_emb)
names(df_nonfin_emb)

# there are 5 unique levels of the wh column
length(unique(df_nonfin_emb$Wh))

table(df_nonfin_emb$Wh)

  # how  what  when where   who 
  # 100    26     1     5     3 

View(df_nonfin_emb["Sentence"])
# 135/30 = 4.5
# 4 lists of 30
# 1 list of 15
# OR
# 5 lists of 20
# 1 lists of 35

# Double check that there are no complex WH that are nonfinite
df_which = d %>%
  filter((WhPhaseType == "complex") & (QuestionType == "embedded") & (Finite != "yes"))

nrow(df_which)

View(df_which["Sentence"])

```

```{r, bring in the embedded verb}
table(df_nonfin_emb)


# Make a single matrix verb column
df_nonfin_emb = df_nonfin_emb %>%
  unite("MatrixVerb", c("MatrixPredVerb", "MatrixPredOther", "MatrixPredParticle"), na.rm = TRUE, sep = " ", remove = FALSE) %>%
  # Remove leading and trailing whitespace
  mutate(MatrixVerb = str_trim(MatrixVerb))

# replace the empty values in MatrixVerb with the value for Aux verb column
df_nonfin_emb$MatrixVerb = ifelse(df_nonfin_emb$MatrixVerb=="",df_nonfin_emb$MatrixPredAux,df_nonfin_emb$MatrixVerb)

# Lemmatize the MatrixVerb column
df_nonfin_emb$VerbLemma = lemmatize_words(df_nonfin_emb$MatrixVerb)

```

```{r play around with verbs}
table(df_nonfin_emb$VerbLemma,df_nonfin_emb$Wh)

# get the frequency of the matrix verbs
verb_counts = df_nonfin_emb %>%
  group_by(VerbLemma) %>%
  summarize(count = n()) %>%
  View()

# look at a particular case
verb = df_nonfin_emb %>%
  filter(VerbLemma == "penetrate")
# View only a subset of the columns
View(verb[,c("Sentence","VerbLemma","Question")])

vs = subset(df_nonfin_emb, df_nonfin_emb$VerbLemma == "know")
vf = filter(df_nonfin_emb, df_nonfin_emb$VerbLemma == "know")
View(vf)
```


```{r, Bring the context in}
contexts = read.csv("swbd_contexts.csv")
head(contexts)
# subset to the relevant contexts
contexts_nf = contexts %>%
  filter(TGrepID %in% df_nonfin_emb$Item_ID)


```

### Scratch
```{r, Scratch}
# Load in the .csv with the contexts removed
# d = read.csv("swbd_nocntxt.csv",header=T)
View(d)

table(d$trace)

n = d %>%
  filter(Trace == "")

n = subset(d, d$Trace == "")
n = filter(d, d$Trace == "")

# old
nrow(d) # 10667.....10278....10192 (added MACRO (@WH > /^WH/)...10199 (@WH >> /^WH)
head(d)
str(d)
names(d)

table(d$WhAdvP,d$QuestionType)

table(d$QuestionType)
# 650 cleft
View(d[d["Item_ID"] == "138690:33"])

(TOP 
  (S 
    (NP-SBJ (DT That)) 
    (VP 
      (BES 's) 
      (NP-PRD 
          (NP (CD one)) 
          (PP 
              (IN of) 
              (NP 
                  (NP 
                      (PRP$ my) 
                      (JJ favorite) 
                      (NNS things)) 
                  (SBAR 
                      (WHNP-1 (-NONE- 0)) 
                      (S 
                          (NP-SBJ (-NONE- *)) 
                          (EDITED 
                              (RM (-DFL- \[)) 
                              (VP-UNF (TO to)) 
                              (, ,) 
                              (IP (-DFL- \+))) 
                          (VP (TO to) 
                              (RS (-DFL- ])) 
                              (VP 
                                  (VB serve) 
                                  (NP (-NONE- *T*-1)))))))))) (. .) (-DFL- E_S)))



# exclude were & were
# "whose","whereabouts","whatever","which")) because exhaustivity questions doesn't arise
table(root$Wh)

# convert all columns to factor
d <- as.data.frame(unclass(d))

str(d)
table(d$QuestionType)
# Make sure there are none without a tag
nrow(subset(d, d$QuestionType==""))
# 
#  adjunct       cleft  embadjunct    embedded exclamation    fragment    relative        
#         775         586        2401        2432          34         126        1378        root     subject 
#         1719         748 


nrow(subset(d,d$QuestionType=="cleft")) #650 --> 660
nrow(subset(d,d$QuestionType=="embedded")) #2357 --> 1640

# randomly sample an embedded clause
d_emb = subset(d, d$QuestionType=="embedded")
# View(sample_n(d_emb,10))
d_crit = d_emb %>%
  filter(Wh %in% c("who","where","how"))
nrow(d_emb) # 3018 --> 2421 --> 2357 --> 1692 (after removing SBAR-NOM)
nrow(d_crit) #1087 --> 954 --> 912 --> 840 (after removing SBAR-NOM)


set.seed(123)
set.seed(321)
se <- sample_n(d_emb,20)
View(se)

View(se[,c("Item_ID","Sentence","MatrixSubject","SentenceParse")])
View(se[,c("Item_ID","Sentence","JustMatrixClause","MatrixPredAux","MatrixPredVerb","MatrixPredOther","MatrixPredParticle","SentenceParse")])




# shouldnt be embedded:
d[d["Item_ID"] == "138690:33"]
nrow(d)
```
(TOP (S (CC But) 
        (NP-SBJ (PRP you)) 
        (VP (VBP wonder) 
            (SBAR (WHADVP (WRB how) (, ,) (UH well)) 
                  (, ,) 
                  (S-UNF (NP-SBJ (DT this) (NN thing))))) (, ,) (-DFL- N_S)))

Take a random sample of 200.
```{r}
set.seed(123)
s <- sample_n(d, 200)
View(s)
View(s[,c("Item_ID","QuestionType","Sentence","Question","SentenceParse")])

nrow(s)
# write to CSV

write.csv(s, "whq_sample_200.csv",row.names = TRUE)

s_emb = subset(s, s$QuestionType=="embedded")
View(s_emb)

```
https://github.com/thegricean/corpus_implicatures/tree/master/or/experiments/4_implicature_exp/experiments/02_main/experiment_00/js

https://github.com/thegricean/corpus_implicatures/blob/master/some/experiments/main_experiments/speaker_knowledge/experiment_01/public/js/stimuli.js
https://raw.githubusercontent.com/leylakursat/some_without_context/master/experiment/corpora/corpus1.txt

https://thegricean.github.io/corpus_implicatures/or/experiments/4_implicature_exp/experiments/02_main/experiment_00/index.html


Reproduce the same set
```{r}
# the original DF i sent jd
sa <- read.csv("whq_sample_200_A.csv", header=TRUE)


sa = sa[order(sa$Item_ID),]

# this will remove any columns that aren't shared 
ddnew = semi_join(sa, d, by=c("Item_ID"))
# drop that first column
ddnew = ddnew[-c(1)]
write.csv(ddnew, "whq_sample_200_neworig.csv",row.names = TRUE)

# try to check if they're the same IDs

ddnew_names = ddnew$Item_ID
sa_names = sa$Item_ID
length(sa_names)

all.equal(ddnew_names,sa_names)

View(ddnew)

# this doesn't remove any columns that aren't in sa
snew = d %>%
  filter(Item_ID %in% sa$Item_ID)

View(snew)
write.csv(snew, "whq_sample_200_neworig.csv",row.names = TRUE)
# save it to a csv file and provide an annotation guide for what 
# the different types of features should be
# overleaf. 
# 
```

# some embedded cases aren't printing a matrix verb
```{r}
emb <- subset(d, d$QuestionType=="embedded")
nrow(emb)


enmv = emb %>%
  filter(MatrixPred1 %in% c(""))
nrow(enmv) # 3333.....0! fixed
View(enmv)

```
Take a look at cases where there is no questionType assigned.
```{r}
no_qt = subset(d, d$QuestionType=="")
nrow(no_qt) # 1016....819....20....18...0!
View(no_qt)
```
Look at the modal and non-modal cases
```{r}

mod = subset(d, d$ModalPresent=="yes")
nrow(mod) # 895

nmod = subset(d, d$ModalPresent=="no")
nrow(nmod) # 9235

table(d$ModalPresent)

nf2 <- subset(d, d$Finite=="no") # YES THESE ARE ALL GOOD
nrow(nf2) #190....186?
View(nf2)
# sanity check
nf <- subset(d, d$Finite!="yes") 
nrow(nf) #186
View(nf)

# Do these return all the same ?
all.equal(nf,nf2) # TRUE
````
cases that are tagged neither as modal or non-modal



````{r}
notmod = subset(d, d$ModalPresent!="no" & d$ModalPresent!="yes")
nrow(notmod)
View(notmod)
str(d)
notmodcomp = d %>%
  filter(!ModalPresent %in% c("yes","no")) %>%
  filter(WhPhraseType %in% c("complex"))

notmodcomp2 = subset(notmod, notmod$WhPhaseType=="complex")
nrow(notmodcomp2) # so there are non-complex wh that are failing
notmodnotcomp = subset(notmod, notmod$WhPhaseType!="complex")
nrow(notmodnotcomp)
View(notmodnotcomp)

```


```{r}
dd = grepl("can|could|may|might|must|shall|should", d$Sentence)
View(dd)

mods <- ""
for (r in notmod){
    if (grepl("can|could|may|might|must|shall|should", notmod$Sentence))
    mods + r
  }
```

Graphssss

```{r}
ftable(d$QuestionType,d$ModalPresent)

agr = d %>%
  group_by(QuestionType,ModalPresent,Finite) %>%
  mutate(count = count(Sentence), prop_modal= ) %>%
  
  ggplot(d, aes(x=as.factor(QuestionType),y=as.factor(Finite), fill = as.factor(ModalPresent))) +
  geom_bar()
  
View(agr)

```

Looking at embedded questions
```{r}


```
